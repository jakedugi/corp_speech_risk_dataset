{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed48d2bb",
   "metadata": {},
   "source": [
    "# Quote Extraction Pipeline Visualization\n",
    "\n",
    "This notebook loads the JSONL outputs from each stage of the quote extraction pipeline, combines them into a single DataFrame, and provides visualizations to analyze the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66973a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Add project root to sys.path to allow for local module imports\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "print(f\"pandas version: {pd.__version__}\")\n",
    "print(f\"matplotlib version: {matplotlib.__version__}\")\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea011254",
   "metadata": {},
   "source": [
    "## 1. Configuration & Parameters\n",
    "\n",
    "Define paths to the data files and set visualization parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1425134",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# The `run_extraction.py` script saves the data in a `data` directory at the project root.\n",
    "DATA_DIR = Path(\"../../data\")\n",
    "FILES = {\n",
    "    0: DATA_DIR / \"stage0_raw.jsonl\",\n",
    "    1: DATA_DIR / \"stage1_cleaner.jsonl\",\n",
    "    2: DATA_DIR / \"stage2_extractor.jsonl\",\n",
    "    3: DATA_DIR / \"stage3_attributor.jsonl\",\n",
    "    4: DATA_DIR / \"stage4_reranker.jsonl\"\n",
    "}\n",
    "\n",
    "# Visualization settings\n",
    "SCORE_NULL_PLACEHOLDER = -1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e74fbe",
   "metadata": {},
   "source": [
    "## 2. Utility Functions\n",
    "\n",
    "Helper functions to load and prepare the data for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf26d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_stage(stage: int) -> pd.DataFrame:\n",
    "    \"\"\"Loads a single stage's JSONL file into a DataFrame.\"\"\"\n",
    "    file_path = FILES[stage]\n",
    "    if not file_path.exists():\n",
    "        print(f\"Warning: File not found for stage {stage} at {file_path}. Please run `make run` first.\")\n",
    "        return pd.DataFrame()\n",
    "    return pd.read_json(file_path, lines=True)\n",
    "\n",
    "def prepare_dataframe(dfs: list[pd.DataFrame]) -> pd.DataFrame:\n",
    "    \"\"\"Concatenates, cleans, and sorts the DataFrames from all stages.\"\"\"\n",
    "    if not any(not df.empty for df in dfs):\n",
    "        return pd.DataFrame()\n",
    "    full = pd.concat(dfs, ignore_index=True)\n",
    "    full[\"speaker\"] = full[\"speaker\"].fillna(\"<none>\")\n",
    "    full[\"score\"] = full[\"score\"].fillna(SCORE_NULL_PLACEHOLDER)\n",
    "    return full.sort_values([\"stage\", \"speaker\", \"score\"], ascending=[True, True, False])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8b534a",
   "metadata": {},
   "source": [
    "## 3. Data Loading & Preparation\n",
    "\n",
    "Load data from all four stages into a single pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d610587",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [load_stage(s) for s in FILES]\n",
    "full_df = prepare_dataframe(dfs)\n",
    "\n",
    "if not full_df.empty:\n",
    "    print(\"Combined DataFrame shape:\", full_df.shape)\n",
    "    display(full_df.head(10))\n",
    "else:\n",
    "    print(\"DataFrame is empty. Please run `make run` first to generate the data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bf1a57",
   "metadata": {},
   "source": [
    "## 4. Stage-By-Stage Inspection\n",
    "\n",
    "Let's examine the output of each pipeline stage. We'll print a formatted summary of the quotes found at each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecb00e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stage_overview(df):\n",
    "    \"\"\"Iterates through the dataframe and prints a formatted summary.\"\"\"\n",
    "    if df.empty:\n",
    "        print(\"No data to display.\")\n",
    "        return\n",
    "    \n",
    "    for stage, stage_df in df.groupby(\"stage\"):\n",
    "        print(f\"\\n\\n{'='*10} Stage {stage} {'='*10}\")\n",
    "        for speaker, grp in stage_df.groupby(\"speaker\"):\n",
    "            print(f\"\\n-- Speaker: {speaker!r} ({len(grp)} rows) --\")\n",
    "            # Sort by score for display purposes and show top 5\n",
    "            for _, row in grp.sort_values('score', ascending=False).head(5).iterrows():\n",
    "                score_str = f\"[{row.score:.2f}]\" if row.score >= 0 else \"[---]\"\n",
    "                # For raw text, show a snippet\n",
    "                display_text = str(row.text).replace('\\n', ' ')\n",
    "                if len(display_text) > 120:\n",
    "                    display_text = display_text[:117] + '...'\n",
    "                print(f\"  â€¢ {score_str} {display_text}\")\n",
    "\n",
    "print_stage_overview(full_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1299eb02",
   "metadata": {},
   "source": [
    "## 5. Cross-Stage Comparison & Visualizations\n",
    "\n",
    "Now let's visualize the filtering process across stages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8723203",
   "metadata": {},
   "source": [
    "### 5.1 Quote Survival Rate by Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d4272e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not full_df.empty:\n",
    "    stage_counts = full_df.groupby('stage')['doc_id'].nunique()\n",
    "    stage_labels = {0: 'stage0_raw', 1: 'stage1_cleaner', 2: 'stage2_extractor', 3: 'stage3_attributor', 4: 'stage4_reranker'}\n",
    "    labels = [stage_labels.get(s, str(s)) for s in stage_counts.index]\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    ax = sns.barplot(x=labels, y=stage_counts.values)\n",
    "    ax.set_title('Number of Items Passing Each Stage')\n",
    "    ax.set_ylabel('Count (Log Scale)')\n",
    "    ax.set_yscale('log')\n",
    "    ax.bar_label(ax.containers[0])\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No data to plot.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88cdfe3",
   "metadata": {},
   "source": [
    "### 5.2 Speaker Distribution in Final Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda4c1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not full_df.empty:\n",
    "    final_df = full_df[full_df.stage == 4]\n",
    "    if not final_df.empty:\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        top_speakers = final_df['speaker'].value_counts().nlargest(20).index\n",
    "        speaker_df = final_df[final_df['speaker'].isin(top_speakers)]\n",
    "        ax = sns.countplot(y=speaker_df['speaker'], order=top_speakers, hue=speaker_df['speaker'], legend=False)\n",
    "        ax.set_title('stage4_reranker: Final Quote Count per Speaker (Top 20)')\n",
    "        ax.set_xlabel('Number of Quotes')\n",
    "        ax.set_ylabel('Speaker')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"No quotes survived to the final stage.\")\n",
    "else:\n",
    "    print(\"No data to plot.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db76e3c2",
   "metadata": {},
   "source": [
    "### 5.3 Score Distribution in Final Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbadade",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not full_df.empty:\n",
    "    final_df_with_scores = full_df[(full_df.stage == 4) & (full_df.score >= 0)]\n",
    "    if not final_df_with_scores.empty:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        ax = sns.histplot(final_df_with_scores['score'], bins=20, kde=True)\n",
    "        ax.set_title('stage4_reranker: Distribution of Semantic Scores for Final Quotes')\n",
    "        ax.set_xlabel('Similarity Score')\n",
    "        ax.set_ylabel('Frequency')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"No scored quotes in the final stage to plot.\")\n",
    "else:\n",
    "    print(\"No data to plot.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfef121",
   "metadata": {},
   "source": [
    "## 6. Conclusion\n",
    "\n",
    "This notebook provides a detailed, stage-by-stage analysis of the quote extraction pipeline. The visualizations highlight the filtering effectiveness at each step, from raw text to final, semantically-scored quotes."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
