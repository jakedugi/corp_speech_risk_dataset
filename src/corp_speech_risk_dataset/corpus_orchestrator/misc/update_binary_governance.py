#!/usr/bin/env python3
"""
Binary-Specific Column Governance Updater

This script updates the column governance file with failed features from the
binary feature development pipeline. It reads the iteration results and
automatically adds appropriate blocklist patterns.

Usage:
    python scripts/update_binary_governance.py \
        --results-dir results/binary_feature_development \
        --apply
"""

import argparse
import json
from pathlib import Path
from typing import Dict, List, Set
import datetime


def load_iteration_results(results_dir: Path) -> Dict[str, List[Dict]]:
    """Load all iteration results from the pipeline output."""
    iterations = {}

    reports_dir = results_dir / "reports"
    if not reports_dir.exists():
        print(f"❌ Reports directory not found: {reports_dir}")
        return iterations

    # Load each iteration's results
    for result_file in sorted(reports_dir.glob("iteration_*_results.json")):
        iter_num = result_file.stem.split("_")[1]

        with open(result_file, "r") as f:
            data = json.load(f)

        failed_features = []
        for feature, result in data.get("feature_results", {}).items():
            if not result.get("overall_pass", True):
                failed_features.append(
                    {
                        "feature": feature,
                        "reason": result.get("failure_reason", "unknown"),
                        "iteration": iter_num,
                    }
                )

        iterations[iter_num] = failed_features

    return iterations


def group_features_by_reason(iterations: Dict[str, List[Dict]]) -> Dict[str, Set[str]]:
    """Group failed features by their failure reason."""
    reason_groups = {}

    for iter_num, failures in iterations.items():
        for failure in failures:
            reason = failure["reason"]
            feature = failure["feature"]

            if reason not in reason_groups:
                reason_groups[reason] = set()
            reason_groups[reason].add(feature)

    return reason_groups


def generate_governance_patterns(reason_groups: Dict[str, Set[str]]) -> List[str]:
    """Generate regex patterns for column governance."""
    patterns = []

    # Header
    patterns.append(
        f"    # Binary feature validation failures - {datetime.datetime.now().strftime('%Y-%m-%d')}"
    )
    patterns.append("    # Auto-generated by unified binary pipeline")

    # Sort reasons by severity/importance
    reason_order = [
        # 'outcome_leakage',  # association != leakage for case-outcome framing
        "court_leakage",
        "size_biased",
        "too_sparse",
        "too_many_missing",
        "weak_mi",
        "weak_auc",
        "unstable",
        "unknown",
    ]

    # Add patterns for each reason
    for reason in reason_order:
        if reason in reason_groups and reason_groups[reason]:
            patterns.append(f"    # {reason.replace('_', ' ').title()}")

            for feature in sorted(reason_groups[reason]):
                escaped_feature = feature.replace("_", r"\_")
                patterns.append(
                    f'    r"^{escaped_feature}$",  # Binary validation: {reason}'
                )

            patterns.append("")  # Empty line between groups

    return patterns


def update_governance_file(patterns: List[str], backup: bool = True) -> bool:
    """Update the column governance file."""
    governance_file = Path(
        "src/corp_speech_risk_dataset/fully_interpretable/column_governance.py"
    )

    if not governance_file.exists():
        print(f"❌ Column governance file not found: {governance_file}")
        return False

    # Create backup if requested
    if backup:
        backup_file = governance_file.with_suffix(
            f'.py.backup.{datetime.datetime.now().strftime("%Y%m%d_%H%M%S")}'
        )
        governance_file.rename(backup_file)
        print(f"📁 Backup created: {backup_file}")

        # Copy back to original location
        with open(backup_file, "r") as f:
            content = f.read()
        with open(governance_file, "w") as f:
            f.write(content)

    # Read current content
    with open(governance_file, "r") as f:
        content = f.read()

    # Find BLOCKLIST_PATTERNS section
    patterns_start = content.find("BLOCKLIST_PATTERNS = [")
    if patterns_start == -1:
        print("❌ Could not find BLOCKLIST_PATTERNS in governance file")
        return False

    patterns_end = content.find("]", patterns_start)
    if patterns_end == -1:
        print("❌ Could not find end of BLOCKLIST_PATTERNS")
        return False

    # Check if binary patterns already exist
    if "Binary feature validation failures" in content:
        print("⚠️  Binary validation patterns already exist. Removing old ones...")

        # Find and remove old binary patterns
        binary_start = content.find("# Binary feature validation failures")
        if binary_start > patterns_start and binary_start < patterns_end:
            # Find the next section or end
            next_section = content.find("    #", binary_start + 1)
            if next_section == -1 or next_section > patterns_end:
                next_section = patterns_end

            # Remove old patterns
            content = content[:binary_start].rstrip() + "\n" + content[next_section:]

            # Update end position
            patterns_end = content.find("]", patterns_start)

    # Insert new patterns before the closing bracket
    insert_point = content.rfind("\n", patterns_start, patterns_end)

    new_content = (
        content[:insert_point] + "\n" + "\n".join(patterns) + content[insert_point:]
    )

    # Write updated content
    with open(governance_file, "w") as f:
        f.write(new_content)

    # Count added patterns
    pattern_count = len([p for p in patterns if 'r"^' in p])
    print(
        f"✅ Updated column governance with {pattern_count} binary validation patterns"
    )

    return True


def create_summary_report(iterations: Dict, reason_groups: Dict, output_file: Path):
    """Create a summary report of governance updates."""
    with open(output_file, "w") as f:
        f.write("# Binary Feature Governance Update Summary\n\n")
        f.write(f"Generated: {datetime.datetime.now()}\n\n")

        # Overall statistics
        total_failed = sum(len(features) for features in reason_groups.values())
        f.write(f"## Statistics\n\n")
        f.write(f"- Total failed features: {total_failed}\n")
        f.write(f"- Failure categories: {len(reason_groups)}\n")
        f.write(f"- Iterations analyzed: {len(iterations)}\n\n")

        # Failures by reason
        f.write("## Failures by Reason\n\n")
        for reason, features in sorted(
            reason_groups.items(), key=lambda x: len(x[1]), reverse=True
        ):
            f.write(
                f"### {reason.replace('_', ' ').title()} ({len(features)} features)\n\n"
            )
            for feature in sorted(features):
                clean_name = feature.replace("interpretable_", "")
                f.write(f"- `{clean_name}`\n")
            f.write("\n")

        # Iteration summary
        f.write("## Iteration Summary\n\n")
        for iter_num, failures in sorted(iterations.items()):
            f.write(f"### Iteration {iter_num}\n")
            f.write(f"- Failed features: {len(failures)}\n")

            # Count by reason
            reason_counts = {}
            for failure in failures:
                reason = failure["reason"]
                reason_counts[reason] = reason_counts.get(reason, 0) + 1

            for reason, count in sorted(reason_counts.items()):
                f.write(f"  - {reason}: {count}\n")
            f.write("\n")


def main():
    """Main execution function."""
    parser = argparse.ArgumentParser(
        description="Update column governance with binary validation failures",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=__doc__,
    )

    parser.add_argument(
        "--results-dir",
        type=str,
        required=True,
        help="Directory containing binary pipeline results",
    )

    parser.add_argument(
        "--apply",
        action="store_true",
        help="Apply the updates to column governance (default: preview only)",
    )

    parser.add_argument(
        "--no-backup",
        action="store_true",
        help="Do not create backup of governance file",
    )

    args = parser.parse_args()

    results_dir = Path(args.results_dir)
    if not results_dir.exists():
        print(f"❌ Results directory not found: {results_dir}")
        return 1

    print("🔍 Loading iteration results...")
    iterations = load_iteration_results(results_dir)

    if not iterations:
        print("❌ No iteration results found!")
        return 1

    print(f"✓ Loaded results from {len(iterations)} iterations")

    # Group features by reason
    reason_groups = group_features_by_reason(iterations)

    # Generate patterns
    patterns = generate_governance_patterns(reason_groups)

    # Preview
    print("\n📋 GOVERNANCE UPDATE PREVIEW")
    print("=" * 60)
    print("The following patterns will be added:\n")
    for pattern in patterns[:20]:  # Show first 20 lines
        print(pattern)
    if len(patterns) > 20:
        print(f"... and {len(patterns) - 20} more lines")

    # Create summary report
    summary_file = results_dir / "governance_update_summary.md"
    create_summary_report(iterations, reason_groups, summary_file)
    print(f"\n📄 Summary report saved to: {summary_file}")

    if args.apply:
        print("\n🔄 Applying governance updates...")
        success = update_governance_file(patterns, backup=not args.no_backup)
        if success:
            print("✅ Column governance successfully updated!")
        else:
            print("❌ Failed to update column governance")
            return 1
    else:
        print("\n👁️  PREVIEW ONLY - no changes applied")
        print("📝 Use --apply flag to update column governance")

    return 0


if __name__ == "__main__":
    exit(main())
